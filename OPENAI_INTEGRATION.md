# OpenAI Integration Setup Guide

## ‚úÖ Integration Status

The OpenAI integration is **correctly configured** and ready to use. The system supports both:
1. **Standard OpenAI API** (default)
2. **OpenAI Proxy** (when on VPN)

## üîß Configuration

### Option 1: Standard OpenAI API (Default)

```bash
# .env file
OPENAI_API_KEY=your-actual-openai-key
OPENAI_API_BASE=https://api.openai.com/v1
DEFAULT_LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1
```

### Option 2: OpenAI Proxy (VPN Required)

```bash
# .env file
OPENAI_API_KEY=your-mw-api-key
OPENAI_API_BASE=https://aikeys.maibornwolff.de/
DEFAULT_LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1
```

## üß™ Testing the Integration

### 1. Quick Test Script

```bash
cd /Users/eduardo.pertierrapuche/Development/mw-randd/agent-orchestration-app
source venv/bin/activate
python scripts/test_llm.py
```

**Expected Output:**
```
üîß Testing LLM Configuration...
API Base: https://api.openai.com/v1
Model: gpt-4o-mini
Temperature: 0.1

‚úÖ LLM Instance Created:
  - Model: gpt-4o-mini
  - Temperature: 0.1
  - Max Tokens: 4096

‚úÖ Test Response: Hello from OpenAI API!
```

### 2. API Health Check

```bash
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model": "gpt-4o-mini",
  "vector_store": "chromadb",
  "api_base": "https://api.openai.com/v1"
}
```

## üìù Usage in Code

The `get_llm()` factory automatically uses your configured settings:

```python
from app.config.llm import get_llm, get_embedding_model

# Default LLM (uses settings)
llm = get_llm()

# Override temperature for specific use cases
creative_llm = get_llm(temperature=0.7)  # More creative
precise_llm = get_llm(temperature=0.0)   # Deterministic

# Get embeddings
embeddings = get_embedding_model()
```

## üîç Verification Checklist

- [x] ‚úÖ Settings module loads configuration
- [x] ‚úÖ LLM factory creates instances with correct parameters
- [x] ‚úÖ Supports both standard OpenAI and OpenAI API
- [x] ‚úÖ FastAPI server reports configuration in health check
- [ ] ‚ö†Ô∏è **API Key Required** - Replace `OPENAI_API_KEY` in `.env` with valid key

## ‚ö†Ô∏è Current Status

**Integration Code:** ‚úÖ Working  
**API Connection:** ‚ö†Ô∏è Pending valid API key

### Next Steps:

1. **Get Valid API Key:**
   - For Standard OpenAI: https://platform.openai.com/api-keys
   - For MW Proxy: Contact your MW admin

2. **Update `.env` file:**
   ```bash
   # Replace with your actual key
   OPENAI_API_KEY=sk-your-actual-key-here
   ```

3. **Test Connection:**
   ```bash
   make run-local  # Server auto-reloads with new config
   python scripts/test_llm.py
   ```

## üîí Security Notes

- Never commit `.env` file (already in `.gitignore`)
- API key in `.env` is local only
- OpenAI API requires VPN connection
- Standard OpenAI works from anywhere

## üìä Test Results

```
Connection Test: ‚úÖ PASSED (reaches API endpoint)
Authentication: ‚ö†Ô∏è PENDING (valid key needed)
Configuration: ‚úÖ PASSED (all settings loaded)
Factory Pattern: ‚úÖ PASSED (creates LLM instances)
```
